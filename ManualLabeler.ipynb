{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "resident-negative",
   "metadata": {},
   "source": [
    "# Manual Labeling Interface: NLP\n",
    "\n",
    "Sam Showalter\n",
    "\n",
    "2021-06-01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-barcelona",
   "metadata": {},
   "source": [
    "Welcome to hell. This is where you will manually tag 4 articles for humanitarian categories so that we can log performance. Get comfortable, this should be fun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-vehicle",
   "metadata": {},
   "source": [
    "## Recommended Approach\n",
    "\n",
    "- I will send out a picture that maps the label codes to the word labels for your reference. Keep that puppy up on your screen somewhere\n",
    "- I will also generate a \"qual_samples_{your_name}.pkl\" file for you. This will provide you the tokens for your article as well as the predicted labels. The predicted labels will likely not be completely right, which is where you come in\n",
    "- Using the legend, copy over the output into a text file. The script below will print the lines, one at a time, with the predictions. Use this as your starting point, and work your way through them.\n",
    "- Once you are done, copy that list of lists back into Jupyter, and save it in a dictionary where the key is the article name and the values are the list of lists that represent the gold labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "genuine-sensitivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ahead-economics",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.23.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open('artifacts/qual_samples.pkl','rb') as file:\n",
    "    d = pkl.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "regulated-sudan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['pakistan_earthquake', 'dorian_wiki', 'idai_news_article', 'le'])\n"
     ]
    }
   ],
   "source": [
    "print(d.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "incorporate-allocation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['caution_and_advice']\n",
      "1 ['displaced_people_and_evacuations']\n",
      "2 ['infrastructure_and_utility_damage']\n",
      "3 ['injured_or_dead_people']\n",
      "4 ['missing_or_found_people']\n",
      "5 ['not_humanitarian']\n",
      "6 ['other_relevant_information']\n",
      "7 ['requests_or_urgent_needs']\n",
      "8 ['rescue_volunteering_or_donation_effort']\n",
      "9 ['sympathy_and_support']\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i, d['le'].inverse_transform([i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "vulnerable-oakland",
   "metadata": {},
   "outputs": [],
   "source": [
    "crisis = 'dorian_wiki'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "outer-champagne",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "\n",
      "['Hurricane', 'Dorian', 'was', 'an', 'extremely', 'powerful', 'and', 'catastrophic', 'Category', 'Atlantic', 'hurricane', 'which', 'became', 'the', 'most', 'intense', 'tropical', 'cyclone', 'on', 'record', 'to', 'strike', 'the', 'Bahamas', 'and', 'tied', 'for', 'strongest', 'landfall', 'in', 'the', 'Atlantic', 'basin']\n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------------------------------------------------------\n",
      "1\n",
      "\n",
      "['It', 'is', 'also', 'regarded', 'as', 'the', 'worst', 'natural', 'disaster', 'in', 'The', 'Bahamas', 'recorded', 'history', 'It', 'was', 'also', 'one', 'of', 'the', 'most', 'powerful', 'hurricanes', 'recorded', 'in', 'the', 'Atlantic', 'Ocean', 'in', 'terms', 'of', 'minute', 'sustained', 'winds', 'with', 'those', 'winds', 'peaking', 'at', '185', 'mph', '295', 'km']\n",
      "\n",
      "[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
      "---------------------------------------------------------------------------\n",
      "2\n",
      "\n",
      "['In', 'addition', 'Dorian', 'surpassed', 'Hurricane', 'Irma', 'of', '2017', 'to', 'become', 'the', 'most', 'powerful', 'Atlantic', 'hurricane', 'on', 'record', 'outside', 'of', 'the', 'Caribbean', 'Sea']\n",
      "\n",
      "[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
      "---------------------------------------------------------------------------\n",
      "3\n",
      "\n",
      "['Dorian', 'was', 'the', 'fourth', 'named', 'storm', 'second', 'hurricane', 'the', 'first', 'major', 'hurricane', 'and', 'the', 'first', 'Category', 'hurricane', 'of', 'the', '2019', 'Atlantic', 'hurricane', 'season']\n",
      "\n",
      "[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
      "---------------------------------------------------------------------------\n",
      "4\n",
      "\n",
      "['Dorian', 'struck', 'the', 'Abaco', 'Islands', 'on', 'September', 'with', 'maximum', 'sustained', 'winds', 'of', '185', 'mph', '295', 'km', 'tying', 'with', 'the', '1935', 'Labor', 'Day', 'hurricane', 'for', 'the', 'highest', 'wind', 'speeds', 'of', 'an', 'Atlantic', 'hurricane', 'ever', 'recorded', 'at', 'landfall']\n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------------------------------------------------------\n",
      "5\n",
      "\n",
      "['Dorian', 'went', 'on', 'to', 'strike', 'Grand', 'Bahama', 'at', 'similar', 'intensity', 'stalling', 'just', 'north', 'of', 'the', 'territory', 'with', 'unrelenting', 'winds', 'for', 'at', 'least', '24', 'hours']\n",
      "\n",
      "[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
      "---------------------------------------------------------------------------\n",
      "6\n",
      "\n",
      "['The', 'resultant', 'damage', 'to', 'these', 'islands', 'was', 'catastrophic', 'most', 'structures', 'were', 'flattened', 'or', 'swept', 'to', 'sea', 'and', 'at', 'least', '70', '000', 'people', 'were', 'left', 'homeless']\n",
      "\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "---------------------------------------------------------------------------\n",
      "7\n",
      "\n",
      "['After', 'it', 'ravaged', 'through', 'the', 'Bahamas', 'Dorian', 'proceeded', 'along', 'the', 'coasts', 'of', 'the', 'Southeastern', 'United', 'States', 'and', 'Atlantic', 'Canada', 'leaving', 'behind', 'considerable', 'damage', 'and', 'economic', 'losses', 'in', 'those', 'regions']\n",
      "\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "---------------------------------------------------------------------------\n",
      "8\n",
      "\n",
      "['Dorian', 'developed', 'from', 'tropical', 'wave', 'on', 'August', '24', 'over', 'the', 'Central', 'Atlantic']\n",
      "\n",
      "[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
      "---------------------------------------------------------------------------\n",
      "9\n",
      "\n",
      "['The', 'storm', 'moved', 'through', 'the', 'Lesser', 'Antilles', 'and', 'became', 'hurricane', 'north', 'of', 'the', 'Greater', 'Antilles', 'on', 'August', '28']\n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------------------------------------------------------\n",
      "10\n",
      "\n",
      "['Dorian', 'proceeded', 'to', 'undergo', 'rapid', 'intensification', 'over', 'the', 'following', 'days', 'before', 'reaching', 'its', 'peak', 'as', 'Category', 'hurricane', 'with', 'one', 'minute', 'sustained', 'winds', 'of', '185', 'mph', '295', 'km', 'and', 'minimum', 'central', 'pressure', 'of', '910', 'millibars', '26', '87', 'inHg', 'by', 'September']\n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------------------------------------------------------\n",
      "11\n",
      "\n",
      "['It', 'made', 'landfall', 'in', 'the', 'Bahamas', 'in', 'Elbow', 'Cay', 'just', 'east', 'of', 'Abaco', 'Island', 'and', 'again', 'on', 'Grand', 'Bahama', 'several', 'hours', 'later', 'where', 'it', 'remained', 'nearly', 'stationary', 'for', 'the', 'next', 'day', 'or', 'so']\n",
      "\n",
      "[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
      "---------------------------------------------------------------------------\n",
      "12\n",
      "\n",
      "['After', 'weakening', 'considerably', 'Dorian', 'began', 'moving', 'northwestward', 'on', 'September', 'parallel', 'to', 'the', 'east', 'coast', 'of', 'Florida']\n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------------------------------------------------------\n",
      "13\n",
      "\n",
      "['Dwindling', 'in', 'strength', 'the', 'hurricane', 'turned', 'to', 'the', 'northeast', 'the', 'next', 'day', 'and', 'made', 'landfall', 'on', 'Cape', 'Hatteras', 'at', 'Category', 'intensity', 'on', 'September']\n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------------------------------------------------------\n",
      "14\n",
      "\n",
      "['Dorian', 'transitioned', 'into', 'an', 'extratropical', 'cyclone', 'on', 'September', 'before', 'striking', 'first', 'Nova', 'Scotia', 'and', 'then', 'Newfoundland', 'with', 'hurricane', 'force', 'winds', 'on', 'the', 'next', 'day', 'The', 'storm', 'finally', 'dissipated', 'near', 'Greenland', 'on', 'September', '10']\n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------------------------------------------------------\n",
      "15\n",
      "\n",
      "['From', 'August', '26', 'to', 'August', '28', 'the', 'storm', 'affected', 'several', 'parts', 'of', 'the', 'northernmost', 'Lesser', 'Antilles']\n",
      "\n",
      "[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
      "---------------------------------------------------------------------------\n",
      "16\n",
      "\n",
      "['Damaging', 'winds', 'primarily', 'affected', 'the', 'Virgin', 'Islands', 'where', 'gusts', 'reached', '111', 'mph', '179', 'km', 'Extensive', 'precautionary', 'measures', 'were', 'taken', 'to', 'mitigate', 'damage', 'especially', 'in', 'Puerto', 'Rico', 'where', 'one', 'person', 'died']\n",
      "\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "---------------------------------------------------------------------------\n",
      "17\n",
      "\n",
      "['Elsewhere', 'in', 'the', 'Lesser', 'Antilles', 'impacts', 'from', 'the', 'storm', 'were', 'relatively', 'minor']\n",
      "\n",
      "[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
      "---------------------------------------------------------------------------\n",
      "18\n",
      "\n",
      "['In', 'preparation', 'for', 'the', 'storm', 'the', 'states', 'of', 'Florida', 'Georgia', 'South', 'Carolina', 'North', 'Carolina', 'and', 'Virginia', 'all', 'declared', 'state', 'of', 'emergency', 'and', 'many', 'coastal', 'counties', 'from', 'Florida', 'to', 'North', 'Carolina', 'issued', 'mandatory', 'evacuation', 'orders']\n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n",
      "---------------------------------------------------------------------------\n",
      "19\n",
      "\n",
      "['Damage', 'in', 'the', 'Bahamas', 'was', 'catastrophic', 'due', 'to', 'the', 'prolonged', 'and', 'intense', 'storm', 'conditions', 'including', 'heavy', 'rainfall', 'high', 'winds', 'and', 'storm', 'surge', 'with', 'thousands', 'of', 'homes', 'destroyed', 'and', 'at', 'least', '77', 'direct', 'deaths', 'recorded', '74', 'of', 'which', 'occurred', 'in', 'the', 'Bahamas']\n",
      "\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 2, 2, 2]\n",
      "---------------------------------------------------------------------------\n",
      "20\n",
      "\n",
      "['The', 'true', 'death', 'toll', 'is', 'unknown', 'with', '245', 'people', 'still', 'missing', 'as', 'of', 'April', '2020']\n",
      "\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "---------------------------------------------------------------------------\n",
      "21\n",
      "\n",
      "['Dorian', 'is', 'the', 'costliest', 'disaster', 'in', 'Bahamian', 'history', 'estimated', 'to', 'have', 'left', 'behind', 'billion', '2020', 'USD', 'in', 'damage', 'in', 'that', 'country', 'while', 'causing', 'total', 'of', 'billion', 'in', 'damage', 'overall']\n",
      "\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(d[crisis]['tokens'])):\n",
    "    print(j)\n",
    "    print()\n",
    "    print(d[crisis]['tokens'][j])\n",
    "    print()\n",
    "    print((d[crisis]['preds'][j]))\n",
    "    print(\"-----\"*15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "nlpenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
